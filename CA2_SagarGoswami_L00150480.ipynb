{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA2_SagarGoswami_L00150480.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMc41jgW61X3KawUpOIoMHW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar625/Artificial-Intelligence-2-Assesment/blob/master/CA2_SagarGoswami_L00150480.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4_RDeeEHNSt",
        "colab_type": "text"
      },
      "source": [
        "# Class Assesment 2. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Name: Sagar Goswami.\n",
        "Student number: L00150480\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Q1**\n",
        "  * Topic Modeling using Linear discriminant analysis (LDA)\n",
        "\n",
        "  * Topic Modeling using Non-negative matrix factorization(NMF) with include two techniques 'Generalized Kullback-Leibler divergence' and 'Frobenius norm'.\n",
        "\n",
        "  * Term frequency and Inverse documnet frequency (Td-idf) and Count Vector or simply Term frequency as Text Features.\n",
        "\n",
        "  * Spacy library is also used for text tokenization and preprocessing like Stopword removal, Lemmatization, Punctuation removal.\n",
        "\n",
        "  * Topic modeling code can be configured for samples, features, components and top words.\n",
        "\n",
        "  * Log Likelihood:  -15551059.92269141 and Perplexity:  4517.373157543353 is achieved for LDA.\n",
        "\n",
        "* I created the labeled dataset with 4,000,00 records and chose NMF topics to create the labeled dataset.Visualization of word count of frequent words was less informative so I decided to keep out of the assignment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4NahWZPlXxy",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ce65a13d-9585-4c17-d66b-ca0963b3e7d8"
      },
      "source": [
        "# I love Colab.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-858532fb-4afa-47ca-940c-473f472eb157\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-858532fb-4afa-47ca-940c-473f472eb157\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving quora_questions.csv to quora_questions.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8MQVTlKpw6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87deeb6e-ced7-4140-d629-552b4eaf6c10"
      },
      "source": [
        "#Importing required Libraries\n",
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load(disable=[\"tagger\", \"parser\", \"ner\"])\n",
        "nlp.max_length = 2000000\n",
        "\n",
        "\n",
        "# The original file have 800000 samples and this configuration can be used to create configured models.\n",
        "n_samples = 200000 #using half of the data.\n",
        "n_features = 10000 #Number of TF-IDF or TF Features.\n",
        "n_components = 13 #The grid search gives 10 as best parameter.\n",
        "n_top_words = 30  # Top words to decide the category of the Topic.\n",
        "\n",
        "\n",
        "# New stop words list \n",
        "customize_stop_words = ['well', 'thing', 'like']\n",
        "\n",
        "# Mark them as stop words\n",
        "for w in customize_stop_words:\n",
        "    nlp.vocab[w].is_stop = True\n",
        "\n",
        "def spacy_tokenizer(sentence):\n",
        "    ''' Tokenize the questions. Lemmetize the tokens and remove Stopwords, Puncuations, Spaces and unit length words.'''\n",
        "    return [word.lemma_ for word in nlp(sentence) if not (word.like_num or word.is_stop or word.is_punct or word.is_space or len(word)==1)]\n",
        "\n",
        "\n",
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    '''To print the N top words from given number of Topics'''\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        message = \"Topic #%d: \" % topic_idx\n",
        "        message += \" \".join([feature_names[i]\n",
        "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
        "        print(message)\n",
        "    print()\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "t0 = time()\n",
        "data = pd.read_csv(\"quora_questions.csv\")  #Loading data having 808578 questions.\n",
        "data_samples = data.question\n",
        "data_samples = data_samples[:n_samples]\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "# Use tf-idf features for NMF.\n",
        "print(\"Extracting tf-idf features for NMF...\")\n",
        "tfidf_vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer,max_df=0.95, min_df=2,\n",
        "                                   max_features=n_features,stop_words='english'\n",
        "                                    )\n",
        "t0 = time()\n",
        "tfidf = tfidf_vectorizer.fit_transform(data_samples.values.astype('U'))\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "# Use tf (raw term count) features for LDA.\n",
        "print(\"Extracting tf features for LDA...\")\n",
        "tf_vectorizer = CountVectorizer(tokenizer=spacy_tokenizer,max_df=0.95, min_df=2,\n",
        "                                max_features=n_features,stop_words='english')\n",
        "t0 = time()\n",
        "tf = tf_vectorizer.fit_transform(data_samples.values.astype('U'))\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "print()\n",
        "\n",
        "\n",
        "# most frequent words\n",
        "word_count = pd.DataFrame({'word': tf_vectorizer.get_feature_names(), 'count': np.asarray(tf.sum(axis=0))[0]})\n",
        "\n",
        "word_count.sort_values('count', ascending=False).set_index('word')[:20].sort_values('count', ascending=True).plot(kind='barh')\n",
        "\n",
        "\n",
        "# Fit the NMF model\n",
        "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
        "      \"n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "t0 = time()\n",
        "nmf_fn = NMF(n_components=n_components, random_state=1,\n",
        "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "print_top_words(nmf_fn, tfidf_feature_names, n_top_words)\n",
        "\n",
        "# Fit the NMF model\n",
        "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
        "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "t0 = time()\n",
        "nmf_kl = NMF(n_components=n_components, random_state=1,\n",
        "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
        "          l1_ratio=.5).fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "print_top_words(nmf_kl, tfidf_feature_names, n_top_words)\n",
        "\n",
        "print(\"Fitting LDA models with tf features, \"\n",
        "      \"n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
        "                                learning_method='online',\n",
        "                                learning_offset=50.,\n",
        "                                random_state=0)\n",
        "t0 = time()\n",
        "lda.fit(tf)\n",
        "print(\"Log Likelihood: \", lda.score(tf))\n",
        "print(\"Perplexity: \", lda.perplexity(tf))\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "print(\"\\n\\nTopics in LDA model:\")\n",
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "print_top_words(lda, tf_feature_names, n_top_words)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "done in 1.019s.\n",
            "Extracting tf-idf features for NMF...\n",
            "done in 19.388s.\n",
            "Extracting tf features for LDA...\n",
            "done in 18.346s.\n",
            "\n",
            "Fitting the NMF model (Frobenius norm) with tf-idf features, n_samples=200000 and n_features=10000...\n",
            "done in 24.920s.\n",
            "\n",
            "Topics in NMF model (Frobenius norm):\n",
            "Topic #0: quora question answer ask google need improvement delete mark post easily interview add follow user search writer view googling picture use write topic instead stupid change collapse come block profile\n",
            "Topic #1: money online earn black note youtube rupee easy ban home r free help make internet investment way job website curb start bank corruption video app invest save site market quora\n",
            "Topic #2: life purpose important change live real moment day want earth work happy death lesson decision planet balance thing experience department position regret differ wrong embarrass human big think happen sex\n",
            "Topic #3: learn language programme start book machine python beginner java code hack want read datum market computer resource business web c++ online development website play game site lesson new english guitar\n",
            "Topic #4: india pakistan war note ban rupee world country job place engineer company indian happen r buy business work start olympics china visit spotify government economy affect available state laptop market\n",
            "Topic #5: know love day new thing girl employee time year fall feel sex friend guy person want like old man resolution woman fact possible boy mind girlfriend blow exist relationship pregnant\n",
            "Topic #6: mean word say dream sentence hindi phrase song guy symbol girl urdu japanese love term iq spanish facebook come messenger actual marathi exactly surgical person strike period blue punjabi tamil\n",
            "Topic #7: trump donald win clinton president hillary election vote presidential happen think presidency america elect usa affect debate student war support state unite racist u.s chance wrong obama run international supporter\n",
            "Topic #8: way weight lose fast easy gain suicide commit month fat increase pound reduce study healthy quick painless account prepare height rid hack exercise loss week kg belly body quickly invest\n",
            "Topic #9: difference chinese culture engineer similarity western love science main computer major datum software script c++ sentence language basic example infatuation java current web type company python word account mass window\n",
            "Topic #10: good book movie time work read engineer job watch bad website song idea study year sex company make software favorite college provider position department panel installation balance solar hollywood write\n",
            "Topic #11: people think stop hate care world believe mind google flat use easily ask blow chinese live country black earth white instagram allow feel worry want exist vote sex god search\n",
            "Topic #12: english improve speak skill write pronunciation communication fluently language word fluent native vocabulary song ability fluency speaker enhance translate subtitle sentence specifically aspect need literature way public grammar watch practice\n",
            "\n",
            "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=200000 and n_features=10000...\n",
            "done in 31.785s.\n",
            "\n",
            "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
            "Topic #0: quora question account answer ask need facebook google numb instagram view create delete whatsapp problem password internet email interview follow message picture gmail post block photo list kind send add\n",
            "Topic #1: money online company business earn market car card black bank pay help school high build play social cost hard product website course invest worth stock sell free test start open\n",
            "Topic #2: life live change important big human wrong experience great earth want real exist right end purpose relationship consider history leave true long death child actually today theory happy moment successful\n",
            "Topic #3: learn start language programme book datum code web java hack computer python machine beginner preparation design development self math program structure c++ method source ias developer science resource develop basic\n",
            "Topic #4: india world indian country war place note compare effect visit state china ban r government pakistan reason pro rupee city modi average future usa economy advantage support benefit laptop currency\n",
            "Topic #5: know love girl day feel sex woman thing man friend person old guy tell fall new year girlfriend stop sleep date fact mind employee pregnant talk deal parent period boyfriend\n",
            "Topic #6: mean word sentence dream say white energy come dark eye wear light term iq color japanese exactly blood line mix sign blue black matt sound heart spanish red phrase dog\n",
            "Topic #7: way trump happen lose weight donald win president clinton hillary fast election vote die easy gain control america presidential suicide kill overcome commit run affect obama chance think fear cause\n",
            "Topic #8: engineer prepare study job increase exam eat month rid food college safe cat hair water height body mechanical score fat grow service mba reduce hotel drink class bangalore long gate\n",
            "Topic #9: difference example different type function culture science window computer value law main animal file determine cell application force calculate current mass battle non convert chemical relate formula power plant equation\n",
            "Topic #10: good time year book read student university new make favorite look travel youtube game video site website free long job tip major resolution software possible process gift idea project college\n",
            "Topic #11: people work think use phone app buy android stop iphone mobile bad believe laptop dog hate god chinese hear care smart common apple famous music allow jio camera sim rich\n",
            "Topic #12: movie english improve write watch speak song skill download review tv story series bollywood communication hollywood public favourite power letter anime hindi actor torrent episode memory pronunciation fluently site horror\n",
            "\n",
            "Fitting LDA models with tf features, n_samples=200000 and n_features=10000...\n",
            "Log Likelihood:  -7168973.509335113\n",
            "Perplexity:  3489.1256325711397\n",
            "done in 185.628s.\n",
            "\n",
            "\n",
            "Topics in LDA model:\n",
            "Topic #0: india year note old woman man improve black state indian real human ban r view rupee experience free government affect class skill power leave pakistan review unite meet economy base\n",
            "Topic #1: book movie world new love country example read market word college employee youtube usa child project form self stock series sentence require digital video battle set iit engine mix team\n",
            "Topic #2: life work long want thing different cause tell guy laptop type career course problem home video web effect body girl application block invest purpose gmail mba preparation share bangalore size\n",
            "Topic #3: people think high increase eat reason hair hard follow try list hate fat price height eye film normal expect institute indians strong hand week sydney religion event mumbai exercise structure\n",
            "Topic #4: time money happen online lose possible sex come indian way exam earn datum hack travel great support cat age universe file gain break family star hear short ms free avoid\n",
            "Topic #5: know day weight numb computer wrong month exist science relationship safe download speak non pro believe mind fall train option future hotel parent late period group window light police force\n",
            "Topic #6: good quora question start ask answer business google service war car song water earth build post fact delhi american drink user low network popular civil quality determine easily contact profile\n",
            "Topic #7: job account phone app write win facebook friend game android pay right interview mobile average social process history whatsapp tip message modi send culture chance add available technology rate kill\n",
            "Topic #8: use person stop language english learn look place university president programme school watch important play way major die control say favorite white tv java actually new start development instead industry\n",
            "Topic #9: engineer buy girl help create fast bad energy consider dog date mechanical salary face dark picture search dream space differ handle death store graduate limit fund propose famous field research\n",
            "Topic #10: difference mean trump feel change student donald prepare compare card bank test software china food law america internet sell today vote order center current drug advantage function grow degree international\n",
            "Topic #11: way learn company need website instagram iphone true delete product end easy mark cost run rid design score city story open program sleep deal level join worth photo hour management\n",
            "Topic #12: live study big clinton hillary site visit idea term code make password email apply plan drive god chinese remove girlfriend election benefit music want kind talk presidential apple choose house\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAD4CAYAAACjd5INAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de7xWZZn/8c/XLYEcBBF+hmJtKxJROcjWEQUTLccc06Z0UklFSzIb0ZlRx3KmsazRsjyOpuTgIckMTSWb0lQQxOPeHEVFLSmR8oCCIkII1++PdW953O4j+3n2c/q+X6/ntde6n3W4lu249r3Wva5bEYGZmVmxbVXsAMzMzMAJyczMSoQTkpmZlQQnJDMzKwlOSGZmVhK2LnYA5WzAgAFRW1tb7DDMzMpKQ0PDaxExsGm7E1In1NbWUl9fX+wwzMzKiqQ/NdfuW3ZmZlYSyr6HJOnhiNivA9sfCJwVEYdLOgIYFhEXbcm5F7+0mtpzf7Mlu5qZla1lF/1DQY5b9gmpI8momX1nADPyGI6ZmW2hsr9lJ2lN+nmgpFmSbpP0jKRpkpS+OzS1zQO+kLPvREn/k5Y/J+kxSfMl3Sdph6JckJlZlSr7hNTEKOBMYBjwMWB/ST2AnwKfA0YDH25h34eAfSNiFPAL4JzmNpI0SVK9pPqNa1fnO34zs6pV9rfsmng8IpYDSFoA1AJrgBci4rnUfjMwqZl9BwO3ShoEfAh4obkTRMQUYApA90FDXJnWzCxPKq2HtD5neSMdS7hXAv8TEXsCXwN65DMwMzNrXaX1kJrzDFAr6eMR8Qfg2Ba26wu8lJZPbM+B99ypL/UFGm1iZlZtKq2H9AERsY7sFt1v0qCGV1rY9HxguqQG4LUuCs/MzBJ5gr4tV1dXF67UYGbWMZIaIqKuaXvF95DMzKw8OCGZmVlJqIZBDS2SNBGoi4h/3pL9XTrIzIqpUCV8isU9JDMzKwklnZAk1eaUAXo6lQXqKWm0pAclNUi6J73MiqSRkh6VtEjSHZK2S+2zJF0uaYGkJyXt08y5Bkq6XdIT6bN/V1+vmVk1K+mElOwKXB0RuwFvAt8ge4n1qIgYDUwFvp+2vQn494gYDiwG/ivnOD0jYiRwWtqnqcuBSyNib+CLwHXNBePSQWZmhVEOz5BejIi5aflm4FvAHsDvU+3UGuAvkvoC/SLiwbTtjcD0nOPcAhARsyVtK6lfk/N8GhiWjgmwraTeEbEmdyOXDjIzK4xySEhN/9F/C1gSEWNyG1NC6shxmq5vRVZcdV17A3OlBjOz/CmHW3YfkdSYfI4DHgUGNrZJ6iZp94hYDbwhaVza9njgwZzjfCltPxZYnbbPdS9weuOKpJH5vxQzM2tJOfSQlgLfkDQVeIrs+dE9wBWpV7Q1cBmwhKwG3TWSegJ/BE7KOc46SfOBbsDJzZxnMnCVpEXpmLOBUwtzSWZm1lRJlw6SVAvcHRF7dPI4s8imLc9rnR+XDjIz6ziXDjIzs5JW0gkpIpZ1tneUjnNgR3pH6f2nJzt7XjMza79yeIZUslw6yMzaUmnlfQqpIhKSpP8Evgy8CrwINAD3AdcAPYE/ACdHxBtp9Fxz7Y0v2UI24s7MzLpQSd+yaw9JjZUVRgCfBRoflLVUtaGl9uuB0yNiRFfFbmZmm5V9QgL2B+6KiHUR8Rbwa6AXH6zacEAL1RwOSFUb+kXE7NT+s5ZO5tJBZmaFUQkJqUtFxJSIqIuIupqebRWHMDOz9qqEZ0hzgWslXUh2PYeT1Zp7Q9K4iJhDqtoQEaslNde+StIqSWMj4iFgQntO7NJBZmb5U/YJKSKekDQDWAS8TPZcaDUtV21oqf0kYKqkwIMazMy6XElXamivxqrcKcnMBiZFxLxCn9eVGszMOq6lSg1l30NKpkgaBvQAbuyKZGRmZvlVEQkpIo4rdgxmZtY5HmVnZmYloSJ6SMXi0kFm1hyXC9oyFddDknS2pMlp+VJJD6TlgyRNk/ST9GLrEknfyfnuzpxjfEbSHcW5AjOz6lRxCQmYAzTOGlsH9JbULbXNBs5LozuGA5+SNByYCQyVNDDtdxKb69q9jys1mJkVRiUmpAZgtKRtgfXAI2SJaRxZsvonSfOA+cDuwLDIxr7/DPhyKiM0Bvhtcwd3pQYzs8KouGdIEbFB0gvAROBhshdmxwOfAN4BzgL2ThW+byAbKg5ZcdVfA+uA6RHxbheHbmZW1SouISVzyBLPyWSVGy4h6zltC7wNrJa0A1l18FkAEbFC0grgP4BPt+ckLh1kZpY/lXjLDrKENAh4JCJeJuv1zImIhWS36p4Bfk5WBy/XNODFiHi6K4M1M7MK7SFFxP1At5z1T+YsT2xl17HATwsXmZmZtaQiE9KWkNRAdjvv34odi5lZNXJCSiJidLFjMDOrZpX6DMnMzMpM1feQJG29pUO8XTrIrHUuoWMdUXY9JEnnSXpW0kOSbpF0lqRZkurS9wMkLUvLPSRdL2mxpPmSxqf2iZJmpLJC90vqLel+SfPStkcW7wrNzKpTWfWQJI0GjgFGksU+j+z9opZ8A4iI2FPSUOBeSY0j7vYChkfE65K2Bv4xIt6UNAB4VNKMaGb2QkmTgEkANdsObPq1mZltoXLrIY0D7oiItRHxJjCjje3HAjcDRMQzwJ+AxoT0+4h4PS0L+G9Ji4D7gJ2AHZo7oEsHmZkVRln1kFrxLpuTa4/WNszxds7yBGAgMDqVHlrWgeOYmVkelFtCmg3cIOlCstg/B1wLLANGA48DR+VsP4cs2TyQbtV9BFhKdrsuV1/glZSMxgMfbU8wLh1kZpY/ZXXLLiLmAbcCC8mqcT+RvvoR8HVJ84EBObtcDWwlaXHab2JErG/m0NOAurTdCWSlhczMrAupmef2ZUPS+cCaiPhRMc5fV1cX9fX1xTi1mVnZktSQ5qV7n7LqIZmZWeUqt2dI7xMR5xc7BjMzy48uS0iNt9fI5iSaHRH3SRoHXANsIJul9bvAYcD/RcTZXRXblnKlBrPmuUKDbYku7yFFxLdzVicAF0bEzfDeS6f9I2Jje47VmbI/ZmZWWgr6DCm3zA+wa2q7QdJRkr4K/BNwgaRpkmYAvYEGSV+SNFDS7ZKeSJ/90/7nS/qZpLnAz9rYbmoqK/RHSZNz4jpB0iJJCyX9LLU1exwzM+saBeshtVXmJyKukzQWuDsibkv7rImIkWn558ClEfGQpI8A9wC7pd2HAWMj4p02thsKjAf6AEsl/YSsUsN/APtFxGuS+qdtL2/lOLnX5dJBZmYFUMhbdu+V+QFIPaCO+DQwTFLj+raSeqflGRHxTju2+01672i9pFfIygEdBEyPiNcAcsoHNXuciFiTG1RETAGmAHQfNKR8x8ybmZWYUh5ltxWwb0Ssy21MCePtdm6X+xLsRlq/3maPY2ZmXaOQCamlMj/tdS9wOnAxgKSREbGgE9s1egC4Q9IlEbFSUv/US+rocVw6yMwsjwo2qKGVMj/tNZmsnM8iSU8Bp3Zyu8a4lgDfBx6UtBC4ZEuOY2Zm+VXWpYOKzaWDzMw6zqWDzMyspDkhmZlZSSjlUXZtSu8t9W57y8Jw6SCzzVwuyDrLPSRAUk2xYzAzq3YVk5AknZ1K/iyS9J2c9jslNUhakqosNLavkfTjNNJuTFr/fion9KikHYpyIWZmVaoiEpKkQ4AhwD5kpYpGSzogfX1yRIwG6oDJkrZP7b2AxyJiREQ8lNYfjYgRZO9QndLCuSZJqpdUv3Ht6gJelZlZdamIhAQckj7zyWrmDSVLUJAloYXAo8DOOe0bgdtzjvE34O603ADUNneiiJgSEXURUVfTs28+r8HMrKqV9aCGHCKbxuJ9lSAkHUhWo25MRKyVNAvokb5e12Saiw2x+aWstsoMmZlZnlXKP7r3kKaxiIg1knYim/SvL/BGSkZDgX3zeVKXDjIzy5+KSEgRca+k3YBHUlHVNcCXgd8Bp0p6GlhKdtvOzMxKkEsHdYJLB5mZdZxLB5mZWUlzQjIzs5JQEc+QACT1A46LiKsl7QhcERFHFfKcLh1klc7lgKwrVVIPqR9wGkBErCh0MjIzs/yqmB4ScBHwcUkLgOeA3SJiD0kTgc+TVWIYAvwI+BBwPNkU54dFxOuSPg5cBQwE1gKnRMQzXX8ZZmbVqZJ6SOcCf4iIkcDZTb7bA/gCsDfZbLFrI2IU8AhwQtpmCnB6KjN0FnB1cydx6SAzs8KopB5Sa2ZGxFvAW5JWA79O7YuB4ZJ6A/sB09N7TADdmztQREwhS150HzTEY+bNzPKkWhLS+pzlTTnrm8j+G2wFrEq9KzMzK4JKSkhvAX22ZMeIeFPSC5KOjojpyrpJwyNiYWv7uXSQmVn+VMwzpIhYCcyV9CRw8RYcYgLwlVQZfAlwZD7jMzOz1rl0UCe4dJCZWce5dJCZmZU0JyQzMysJZTuoQVItcHdE7FGsGFw6yCqJywRZsbmHZGZmJaEiEpKkj0maL+lsSb+S9DtJz0n6Yc42x0paLOlJST9IbUdLuiQtnyHpjznHm1ucqzEzq05le8uukaRdgV8AE4FRwMj0cz2wVNKVwEbgB8Bo4A3gXkmfB+YA56RDjQNWpunPxwGzWzjfJGASQM22AwtzUWZmVajce0gDgbuACTkvsd4fEasjYh3wFPBRshp2syLi1Yh4F5gGHBARfwV6S+oD7Az8HDiALCHNae6EETElIuoioq6mZ9+CXpyZWTUp9x7SauDPwFiy5APvLxO0kbav8WHgJGApWRI6GRgD/FtbJ3elBjOz/Cn3HtLfgH8ETpB0XCvbPQ58StIASTXAscCD6bs5ZNW9ZwPzgfHA+ohwKW8zsy5U7gmJiHgbOBz4F2DbFrb5C9n0FDOBhUBDRNyVvp5DdrtudkRsBF4EHip03GZm9n4uHdQJLh1kZtZxLh1kZmYlrdUH/mnIdItdqIiYnPeICkDSmojoLWlH4IqIOCq13wLsDlwfEZcWNUgzsyrX1gi0xvtR+wPDgFvT+tFsHtVWNiJiBdCYjD4M7B0Rn9jS47l0kFUSlw6yYms1IUXEjQCSvg6MTe/wIOkaWnhPp5Q1qX93L7CTpAXA6cAK4Cqyd5vWAqdExDNFCtXMrOq09z2k7chGsL2e1nuntnJ2BFlyGgkg6X7g1Ih4TtLfAVcDBxUzQDOzatLehHQRMF/STEBk1QzOL1RQXU1Sb2A/YHo2ezkA3VvY1qWDzMwKoM2EJGkrsioGf5c+AP+eyu5Uiq2AVY29pdZExBRgCkD3QUM8Zt7MLE/aTEgRsUnSVRExiqxuXMWJiDclvSDp6IiYrqybNDynPl6zXDrIzCx/2vse0v2Svqic+1kVaALwFUkLgSXAkUWOx8ysqrSrUoOkt4BeZMVK16XmiIhmS/VUC1dqMDPruJYqNbRrUENE9Ml/SGZmZpu1e/oJSUeQja6DbG6huwsTkpmZVaN2PUOSdBFwBll1hqeAMyRdWMjAupqkZZIGFDsOM7Nq1d4e0mHAyIjYBCDpRrK5g75ZqMC6UpojqcNcOshKkUsAWbnqSLXvfjnLJTN3t6SzJU1Oy5dKeiAtHyRpmqRjJS2W9KSkH+Tst0bSj9OoujE57dtI+q2kU7r8YszMqlh7E9J/A/Mk3ZB6Rw3A9wsXVofMAcal5Tqgt6Ruqe1Z4AdkJYBGAntL+nzathfwWESMiIjGCfl6A78GbomIn3bVBZiZWfsT0uHAVLJEdBswJiJubX2XLtMAjJa0LbAeeIQsMY0DVpENwHg1FYadxuaBGRuB25sc6y6yqShuaulkkiZJqpdUv3GtZzk3M8uX9iak/00/jwAuB66SdEZhQuqYiNgAvABMBB4m6zGNBz4BLGtl13VpyvJcc4FDW3sBOCKmRERdRNTV9CyZO5dmZmWv3VOYpwf/e5P9Y38q8E5EDC1gbO0m6Xzg5PRZDDxB1nM6DXgUGA28AdwDXBkRdzVO2pdzjGVkPatvA1tHxGltndcvxpqZdVynpjBPUzPMBb5EVmh171JJRskcYBDwSES8TFZNYk5E/AU4F5gJLAQaIqKtenxnANtI+mEhAzYzs/dr77DvRWS9jD2A1cAqSY9ExDsFi6wDIuJ+oFvO+idzlm8Bbmlmn95N1mtzVk/Kf5RmZtaa9pYO+hcASX3IntVcD3yYFuYMMjMz66h2JSRJ/0w2am002UCBqZThFOZmZla62nvLrgdwCdkzmHcLGI+ZmVWpdo+ysw/qPmhIDDrxsmKHYVXOpYKs3HRqlF2xSKqV9EyqEPFsKgX0aUlzJT0naR9J/SXdKWmRpEclDU/7ni9pqqRZkv7YWF4offdlSY9LWiDpWkk1kk6WdFnONqdIurQY121mVo1KOiElnwB+DAxNn+OAscBZwLeA7wDzI2J4Ws+tsjAU+HtgH+C/JHWTtBvZ8PX9I2IkWcWGCcAvgc+lskOQjbSb2jQYV2owMyuMds+HVEQvRMRiAElLgPsjIiQtBmqBjwJfBIiIByRtn8oIAfwmItYD6yW9AuwAHEw2OOOJVJBhG+CViFiTCrMeLulpoFvjeXNFxBRgCmS37Ap21WZmVaYcEtL6nOVNOeubyOLf0M59N6btBdwYEc1NnXEdWS/rGbKh7WZm1kXKISG1ZQ7ZLbcLJB0IvBYRb7ZSju5+4C5Jl0bEK5L6A30i4k8R8ZiknYG9gOFtnXjPnfpS7wfKZmZ5UQkJ6XxgqqRFwFrgxNY2joinJP0HcK+krch6WN8A/pQ2+SXZZIRvFC5kMzNrysO+m5B0N3BpKkfUKhdXNTPruLIc9t2VJPWT9CxZFfM2k5GZmeVXJdyyy4uIWAV8ss0NzcysINxDMjOzkuAeUicsfmk1tef+pthhWJVxqSCrVGXXQ2pnOaFeqWzQ45LmSzoyZ985kualz36p/cBUYui2dOxprU1jbmZm+VeuPaRPAEeTTVn+BJvLCR1B9mLrU8ADEXGypH7A45LuA14BPhMR6yQNIZu4r3Gkxyhgd2AF2ey4+wMPNT2xpEnAJICabQcW7ALNzKpNuSaktsoJDQaOkHRW2r4H8BGyZPM/khpr2OUOYng8IpanYy5Ix/lAQnLpIDOzwijXhNRWOaGNwBcjYmnuTpLOB14GRpDdrlzXwjEbywyZmVkXqdR/dO8BTpd0euo5jYqI+UBfYHlEbJJ0IlDTmZO4dJCZWf6U3aCGdroA6AYsSrf0LkjtVwMnSlpINjXF20WKz8zMmnDpoE5w6SAzs45z6SAzMytpTkhmZlYSKnVQQ5dwpQbrLFddMNvMPaRWSOrUKDwzM2u/iklIkr4r6cyc9e9LOkPS2ZKekLRI0ndyvr9TUoOkJan6QmP7Gkk/TiPxxnTxZZiZVa2KSUjAVOAEgDQT7DHAX4EhwD7ASGC0pAPS9idHxGiy0kGTJW2f2nsBj0XEiIhotnSQpHpJ9RvXri7sFZmZVZGKeYYUEcskrZQ0CtgBmA/sDRySlgF6kyWo2WRJ6B9T+86pfSVZlYbbWzmPSweZmRVAxSSk5DpgIvBhsh7TwcCFEXFt7kaSDgQ+DYyJiLWSZpHVuwNYFxEbuypgMzPLVFpCugP4LlmVhuOAd4ELJE2LiDWSdgI2kJUQeiMlo6HAvltyMpcOMjPLn4pKSBHxN0kzgVWpl3OvpN2AR9L0RmuALwO/A06V9DSwFHi0WDGbmVmmohJSGsywL9lcSQBExOXA5c1s/tnmjhERvQsTnZmZtaZiRtlJGgY8TzY30nPFjsfMzDqmYnpIEfEU8LFix2FmZlumrBNSmp78uIi4Oo2cOysiDm9mu+uAS1LSaulYNwB3R8Rt7T2/SwdZZ7hskNn7lfstu37AaW1tFBFfbS0ZmZlZ8ZV7QroI+LikBcDFQG9Jt0l6RtI0paF1kmZJqkvLa1JZoYWSHpW0Q9ODSrpA0g2uZWdm1nXKPSGdC/whIkYCZwOjgDOBYWTPk/ZvZp9ewKMRMYKsYsMpuV9KuhgYCJzU3AuyLh1kZlYY5Z6Qmno8IpZHxCZgAVDbzDZ/A+5Oyw1NtvlPoG9EnBotTKUbEVMioi4i6mp69s1f5GZmVa7SEtL6nOWNND9oY0NOsmm6zRNkBVj7Fyg+MzNrQVmPsgPeAvrk8Xi/A+4BfiPpkIh4q7WNXTrIzCx/yjohRcRKSXMlPQm8A7ych2NOl9QHmCHpsIh4p9OBmplZm9TCoxJrh7q6uqivry92GGZmZUVSQ0TUNW2vtGdIZmZWppyQzMysJJT1M6SWSPpWRPx3zvrDEbFfvs/j0kG2pVw2yOyDKrWH9K3clUIkIzMzy6+iJSRJ50l6VtJDkm6RdFaTEj8DJC1LyzWSLpb0hKRFkr6W2gdJmi1pgaQnJY2TdBGwTWqblrZbk34qHedJSYslfSm1H5jO/YGyQ2Zm1jWKcstO0mjgGGBkimEeWdWElnwFWB0Re0vqDsyVdC/wBeCeiPh+qjvXMyLmSPrnVE6oqS+kc44ABgBPSJqdvhsF7A6sAOaSlR16qJnYJwGTAGq2HdjBKzczs5YU6xnSOOCOiFgLIGlGG9sfAgyXdFRa7wsMIausMFVSN+DOiFjQxnHGArekGnUvS3oQ2Bt4k1R2KMXTWHboAwkpIqYAUwC6DxriMfNmZnlSaoMa3mXzbcQeOe0CTo+Ie5ruIOkA4B+AGyRdEhE3beG521N2yMzMCqRY/+jOJksgF6YYPgdcCywDRgOPA0flbH8P8HVJD0TEBkmfBF4iu+22PCJ+mm7l7QXcBGyQ1C0iNjQ57xzga5JuBPoDB5BVCR+6JRfh0kFmZvlTlIQUEfMk3QosBF4hu/UG8CPgl+k5Te546uvIbqHNS4MNXgU+DxwInC1pA7AGOCFtPwVYJGleREzIOc4dwJh03gDOiYi/StqihGRmZvlTEqWDJJ0PrImIHxU7lo5w6SAzs45z6SAzMytpJfHgPiLOL3YMZmZWXCWRkMqVSwdZe7hMkFn7+JadmZmVhIruIUmqBe6OiD3S+llAb+B14FSy956eiohjJPUCrgT2ALoB50fEXcWI28ysGlV0QmrFucAuEbFeUr/Udh7wQEScnNoel3RfRLydu6NLB5mZFUa13rJbBEyT9GWyXhJk5YnOTWWDZpFVivhI0x0jYkpE1EVEXU3Pvl0Vr5lZxav0HlJuKSLYXI7oH8iqNHwOOE/SnmTlib4YEUvbe3BXajAzy59K7yG9DPw/Sdun0kKHk13zzhExE/h3skKtvcnKE53eOO2EpFFFitnMrCpVdA8p1b37LlltvJeAZ4Aa4GZJfcl6RVdExCpJFwCXkZUc2gp4gSyBmZlZF6johAQQEVcAV7Rju3eArxU+IjMza06l37IzM7My4YRkZmYloeJv2RWSSwdZS1wuyKzjKq6HJKlW0tOSfippiaR7JW0j6eOSfiepQdIcSUMl1Uh6QZl+kjamGWiRNFvSkGJfj5lZtai4hJQMAa6KiN2BVcAXySbtOz0iRgNnAVdHxEZgKTAMGAvMA8alIeI7R8RzRYnezKwKVeotuxciYkFabiCbbXY/YHp6zQige/o5h+wl2V2AC4FTgAfZPIvt+7h0kJlZYVRqD2l9zvJGoD+wKiJG5nx2S9/PBsYB+wD/B/Qjmxp9TnMHdukgM7PCqNQeUlNvAi9IOjoipqdqDMMjYiHZS7M/A/4YEetSLbuv0Y6XYl06yMwsfyq1h9ScCcBXJC0ElgBHAkTEeuBF4NG03RygD7C4GEGamVUrRUSxYyhbdXV1UV9fX+wwzKyEbdiwgeXLl7Nu3bpih9LlevToweDBg+nWrdv72iU1RERd0+2r5ZadmVlRLF++nD59+lBbW0vOoKqKFxGsXLmS5cuXs8suu7Rrn2q6ZWdm1uXWrVvH9ttvX1XJCEAS22+/fYd6hhWbkCSdKannFuw3UdKOhYjJzKpTtSWjRh297kq+ZXcmcDOwtr07SKoBJgJPAiva2t6lg6wlLh1k1nEVkZAk9QJ+CQwmm+9oOrAjMFPSaxExXtJPgL2BbYDbIuK/0r7LgFuBzwCXAHVk05u/A4xJ01KYmeVFvv+ILfYfP5dddhmTJk2iZ88O35D6gEq5ZXcosCIiRkTEHmQT7a0AxkfE+LTNeWlUx3DgU5KG5+y/MiL2ioibgXpgQnp59gPJSNIkSfWS6jeuXV3YqzIzK3GXXXYZa9e2+0ZUqyolIS0GPiPpB5LGRURzmeKfJM0D5gO7k9Wva3Rre0/kSg1mVm5uuukmhg8fzogRIzj++ONZtmwZBx10EMOHD+fggw/mz3/+MwATJ07ktttue2+/3r17AzBr1iwOPPBAjjrqKIYOHcqECROICK644gpWrFjB+PHjGT9+fLPn7oiKuGUXEc9K2gs4DPiepPtzv5e0C1lB1b0j4g1JNwA9cjZ5u8uCNTPrQkuWLOF73/seDz/8MAMGDOD111/nxBNPfO8zdepUJk+ezJ133tnqcebPn8+SJUvYcccd2X///Zk7dy6TJ0/mkksuYebMmQwYMKDTsVZEQkqj4l6PiJslrQK+CrxFVnHhNWBbsqSzWtIOwGeBWS0crnG/Nrl0kJmVugceeICjjz76vYTRv39/HnnkEX71q18BcPzxx3POOee0eZx99tmHwYMHAzBy5EiWLVvG2LFj8xprRSQkYE/gYkmbgA3A14ExwO8krUiDGuYDz5CVCZrbyrFuAK7xoAYzqzZbb701mzZtAmDTpk387W9/e++77t27v7dcU1PDu+++m/fzV8QzpIi4JyKGp4EIe0dEfURcGRG7Ng5qiIiJEfHJiDg4Ir4QETek9tqIeC3nWLen/Zod1GBmVk4OOuggpk+fzsqVKwF4/fXX2W+//fjFL34BwLRp0xg3bhwAtbW1NDQ0ADBjxgw2bNjQ5vH79OnDW2+9lZdYK6WHZGZWFrp6mPbuu+/Oeeedx6c+9SlqamoYNWoUV155JSeddBIXX3wxAwcO5PrrrwfglFNO4cgjj2TEiBEceuih9OrVq83jT5o0iUMPPZQdd9yRmTNndipWF1ftBBdXNbO2PP300+y2225tb1ihmrv+loqrVsQtO0m1kp7Mw3GWSer8UBEzM+sw37LrBJcOsmK/JW9WSSqih5RsLWmapGPBp4oAAAZDSURBVKcl3Sapp6SDJc2XtFjSVEndAVpqbyRpG0m/lXRKcS7FzCpJtT4a6eh1V1JC2hW4OiJ2I5uy/F/JhnB/KSL2JOsNfl1Sj+bac47TG/g1cEtE/LTpSVw6yMw6okePHqxcubLqklLjfEg9evRoe+Okkm7ZvRgRje8X3Qz8J/BCRDyb2m4EvgHMbKH9srR+F/DDiJjW3EkiYgowBaD7oCHV9RtmZh02ePBgli9fzquvvlrsULpc44yx7VVJCalpclgFbL8Fx5kLHCrp51Ftf9KYWd5169at3TOmVrtKSkgfkTQmIh4BjiOr2v01SZ+IiOeB44EHgaVAbTPtjb6dPlcBp7V2QpcOMjPLn0p6hrQU+Iakp4HtgEuBk4DpkhYDm4BrImJdc+1NjnUGsI2kH3ZZ9GZmVc4vxnaCX4w1M+u4ll6MdULqBElvkfXMyskAsgro5aYc4y7HmKE84y7HmKE8485HzB+NiIFNGyvpGVIxLG0uy5cySfXlFjOUZ9zlGDOUZ9zlGDOUZ9yFjLmSniGZmVkZc0IyM7OS4ITUOVOKHcAWKMeYoTzjLseYoTzjLseYoTzjLljMHtRgZmYlwT0kMzMrCU5IZmZWEpyQtoCkQyUtlfS8pHNLIJ6pkl7JnaRQUn9Jv5f0XPq5XWqXpCtS7Isk7ZWzz4lp++cknVjgmHeWNFPSU5KWSDqjTOLuIelxSQtT3N9J7btIeizFd6ukD6X27mn9+fR9bc6xvpnal0r6+0LGnc5Xk6ZdubuMYl6WpolZIKk+tZX670g/ZVPgPKNsOpwxZRDzrum/cePnTUlndnncEeFPBz5ADfAH4GPAh4CFwLAix3QAsBfwZE7bD4Fz0/K5wA/S8mHAbwEB+wKPpfb+wB/Tz+3S8nYFjHkQsFda7gM8Cwwrg7gF9E7L3YDHUjy/BI5J7dcAX0/Lp5GVrAI4Brg1LQ9LvzvdgV3S71RNgX9P/hX4OXB3Wi+HmJcBA5q0lfrvyI3AV9Pyh4B+pR5zk/hrgL8CH+3quAt+cZX2AcYA9+SsfxP4ZgnEVcv7E9JSYFBaHkT2Ei/AtcCxTbcDjgWuzWl/33ZdEP9dwGfKKW6gJzAP+DuyN9e3bvo7AtwDjEnLW6ft1PT3Jne7AsU6GLgfOAi4O8VQ0jGncyzjgwmpZH9HgL7AC6QBY+UQczPXcAgwtxhx+5Zdx+0EvJizvjy1lZodIuIvafmvwA5puaX4i3Zd6ZbQKLLeRsnHnW59LQBeAX5P1lNYFRHvNhPDe/Gl71eTTYvS1XFfBpxDVkyYFEOpxwzZtDL3SmqQNCm1lfLvyC7Aq8D16fbodZJ6lXjMTR0D3JKWuzRuJ6QqENmfKiU5vl9Sb+B24MyIeDP3u1KNOyI2RsRIsl7HPsDQIofUKkmHA69EREOxY9kCYyNiL+CzZNX8D8j9sgR/R7Ymu33+k4gYBbxNdqvrPSUY83vSc8QjgOlNv+uKuJ2QOu4lYOec9cGprdS8LGkQQPr5SmpvKf4uvy5J3ciS0bSI+FW5xN0oIlaRzUA8BugnqbE2ZG4M78WXvu8LrKRr494fOELSMuAXZLftLi/xmAGIiJfSz1eAO8j+ACjl35HlwPKIeCyt30aWoEo55lyfBeZFxMtpvUvjdkLquCeAIWmE0ofIurczihxTc2YAjSNcTiR7RtPYfkIaJbMvsDp1ye8BDpG0XRpJc0hqKwhJAv4XeDoiLimjuAdK6peWtyF77vU0WWI6qoW4G6/nKOCB9JfmDOCYNKJtF2AI8HghYo6Ib0bE4IioJft9fSAiJpRyzACSeknq07hM9r/tk5Tw70hE/BV4UdKuqelg4KlSjrmJY9l8u64xvq6LuyseklXah2yEybNkzw7OK4F4bgH+Amwg+wvtK2T3/O8HngPuA/qnbUU2G+4fgMVAXc5xTgaeT5+TChzzWLLu/yJgQfocVgZxDwfmp7ifBL6d2j9G9o/z82S3O7qn9h5p/fn0/cdyjnVeup6lwGe76HflQDaPsivpmFN8C9NnSeP/18rgd2Qk2YzVi4A7yUablXTM6Xy9yHrCfXPaujRulw4yM7OS4Ft2ZmZWEpyQzMysJDghmZlZSXBCMjOzkuCEZGZmJcEJyczMSoITkpmZlYT/DyYc0WzRbx/DAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kz3eRRDWdwj",
        "colab_type": "text"
      },
      "source": [
        "**Hyper Parameter Tuning for LDA model. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQtDBXRj0Mq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "39248c25-f122-49f6-b4e3-a66a3da54e71"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define Search Param\n",
        "search_params = {'n_components': [10, 15, 20, 25, 30], 'learning_decay': [.5, .7, .9]}\n",
        "\n",
        "# Init the Model\n",
        "lda_comparison = LatentDirichletAllocation()\n",
        "\n",
        "# Init Grid Search Class\n",
        "lda_comparison = GridSearchCV(lda_comparison, param_grid=search_params)\n",
        "\n",
        "# Do the Grid Search\n",
        "lda_comparison.fit(data_vectorized)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=LatentDirichletAllocation(batch_size=128,\n",
              "                                                 doc_topic_prior=None,\n",
              "                                                 evaluate_every=-1,\n",
              "                                                 learning_decay=0.7,\n",
              "                                                 learning_method='batch',\n",
              "                                                 learning_offset=10.0,\n",
              "                                                 max_doc_update_iter=100,\n",
              "                                                 max_iter=10,\n",
              "                                                 mean_change_tol=0.001,\n",
              "                                                 n_components=10, n_jobs=None,\n",
              "                                                 perp_tol=0.1,\n",
              "                                                 random_state=None,\n",
              "                                                 topic_word_prior=None,\n",
              "                                                 total_samples=1000000.0,\n",
              "                                                 verbose=0),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'learning_decay': [0.5, 0.7, 0.9],\n",
              "                         'n_components': [10, 15, 20, 25, 30]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xa2QQlD0lJe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5f950632-db97-46dc-f7aa-f65cc50c2933"
      },
      "source": [
        "# Best Model which gave highest score \n",
        "best_lda_model = lda_comparison.best_estimator_\n",
        "\n",
        "# Model Parameters is used to store a list of parameter settings dicts for all the parameter candidates\n",
        "print(\"Best Model's Params: \", lda_comparison.best_params_)\n",
        "\n",
        "# Log Likelihood Score\n",
        "print(\"Best Log Likelihood Score: \", lda_comparison.best_score_)\n",
        "\n",
        "# Perplexity\n",
        "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Model's Params:  {'learning_decay': 0.9, 'n_components': 10}\n",
            "Best Log Likelihood Score:  -1583487.353511311\n",
            "Model Perplexity:  2526.2382431927385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C8wOnrlpfOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1852f566-fd4b-4b53-da1f-dc16407d2de0"
      },
      "source": [
        "tf.shape,tfidf.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((400000, 31703), (400000, 31703))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VrEqpG7HF_M",
        "colab_type": "text"
      },
      "source": [
        "#Creating Labeled Dataset \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUFIL1pqLveL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1c49f503-c148-4b18-fab2-7d1c425826f3"
      },
      "source": [
        "frame = {'question': data_samples } \n",
        "  \n",
        "question_df = pd.DataFrame(frame) \n",
        "\n",
        "question_df.head(),len(question_df)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                            question\n",
              " 0  What is the step by step guide to invest in sh...\n",
              " 1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
              " 2  How can I increase the speed of my internet co...\n",
              " 3  Why am I mentally very lonely? How can I solve...\n",
              " 4  Which one dissolve in water quikly sugar, salt..., 200000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wh7oqqj--Ag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7f7a455b-280f-45ca-ac0f-100cd204c448"
      },
      "source": [
        "textfile_topics = nmf_fn.transform(tfidf)\n",
        "topic_list = []\n",
        "# Textfile_topics is a list of arrays containing \n",
        "# all index positions of words for each textfile\n",
        "for popular_index_pos in textfile_topics:\n",
        "    # Get the max index position in each array\n",
        "    # and add to the topic_list list\n",
        "    topic_list.append(popular_index_pos.argmax())\n",
        "\n",
        "# Add a new column to the dataframe\n",
        "question_df[\"Topic number\"] = topic_list\n",
        "\n",
        "question_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>Topic number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  Topic number\n",
              "0  What is the step by step guide to invest in sh...             4\n",
              "1  What is the story of Kohinoor (Koh-i-Noor) Dia...             0\n",
              "2  How can I increase the speed of my internet co...             8\n",
              "3  Why am I mentally very lonely? How can I solve...             0\n",
              "4  Which one dissolve in water quikly sugar, salt...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU2fzojgLGrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_list = {0: \" Major Concepts \", \n",
        "              1: \"Education,Schools & Learning\", \n",
        "              2: \"Business, Work and Careers\", \n",
        "              3: \"Life Self\", \n",
        "              4: \"News, Entertainment & Pop culture\", \n",
        "              5: \"Recreation, Sports, Travel & Activities\", \n",
        "              6: \"Politics, Law, Government, and Judiciary\", \n",
        "              7: \"Medicine & Healthcare\", \n",
        "              8: \"Relationship\", \n",
        "              9: \"Humanities\", \n",
        "              10: \"Literature, Languages & Communication\", \n",
        "              11: \"Major Concepts\", \n",
        "              12: \"Languages\" }\n",
        "\n",
        "topic_no_to_topic = question_df[\"Topic number\"].map(topic_list)\n",
        "question_df[\"Topic desc\"] = topic_no_to_topic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsycn0s7VWxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "13c004bf-f897-4894-94ea-cd7e50f5e5cf"
      },
      "source": [
        "question_df.head(20)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>Topic number</th>\n",
              "      <th>Topic desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>4</td>\n",
              "      <td>News, Entertainment &amp; Pop culture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>0</td>\n",
              "      <td>Major Concepts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>8</td>\n",
              "      <td>Relationship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>0</td>\n",
              "      <td>Major Concepts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>0</td>\n",
              "      <td>Major Concepts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>0</td>\n",
              "      <td>Major Concepts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>4</td>\n",
              "      <td>News, Entertainment &amp; Pop culture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>10</td>\n",
              "      <td>Literature, Languages &amp; Communication</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>When do you use  instead of ?</td>\n",
              "      <td>11</td>\n",
              "      <td>Major Concepts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "      <td>4</td>\n",
              "      <td>News, Entertainment &amp; Pop culture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Method to find separation of slits using fresn...</td>\n",
              "      <td>0</td>\n",
              "      <td>Major Concepts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How do I read and find my YouTube comments?</td>\n",
              "      <td>10</td>\n",
              "      <td>Literature, Languages &amp; Communication</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What can make Physics easy to learn?</td>\n",
              "      <td>3</td>\n",
              "      <td>Life Self</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What was your first sexual experience like?</td>\n",
              "      <td>2</td>\n",
              "      <td>Business, Work and Careers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>What are the laws to change your status from a...</td>\n",
              "      <td>2</td>\n",
              "      <td>Business, Work and Careers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What would a Trump presidency mean for current...</td>\n",
              "      <td>6</td>\n",
              "      <td>Politics, Law, Government, and Judiciary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>What does manipulation mean?</td>\n",
              "      <td>6</td>\n",
              "      <td>Politics, Law, Government, and Judiciary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Why do girls want to be friends with the guy t...</td>\n",
              "      <td>5</td>\n",
              "      <td>Recreation, Sports, Travel &amp; Activities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Why are so many Quora users posting questions ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Major Concepts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Which is the best digital marketing institutio...</td>\n",
              "      <td>4</td>\n",
              "      <td>News, Entertainment &amp; Pop culture</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  ...                                Topic desc\n",
              "0   What is the step by step guide to invest in sh...  ...         News, Entertainment & Pop culture\n",
              "1   What is the story of Kohinoor (Koh-i-Noor) Dia...  ...                           Major Concepts \n",
              "2   How can I increase the speed of my internet co...  ...                              Relationship\n",
              "3   Why am I mentally very lonely? How can I solve...  ...                           Major Concepts \n",
              "4   Which one dissolve in water quikly sugar, salt...  ...                           Major Concepts \n",
              "5   Astrology: I am a Capricorn Sun Cap moon and c...  ...                           Major Concepts \n",
              "6                                 Should I buy tiago?  ...         News, Entertainment & Pop culture\n",
              "7                      How can I be a good geologist?  ...     Literature, Languages & Communication\n",
              "8                 When do you use  instead of ?  ...                            Major Concepts\n",
              "9   Motorola (company): Can I hack my Charter Moto...  ...         News, Entertainment & Pop culture\n",
              "10  Method to find separation of slits using fresn...  ...                           Major Concepts \n",
              "11        How do I read and find my YouTube comments?  ...     Literature, Languages & Communication\n",
              "12               What can make Physics easy to learn?  ...                                 Life Self\n",
              "13        What was your first sexual experience like?  ...                Business, Work and Careers\n",
              "14  What are the laws to change your status from a...  ...                Business, Work and Careers\n",
              "15  What would a Trump presidency mean for current...  ...  Politics, Law, Government, and Judiciary\n",
              "16                       What does manipulation mean?  ...  Politics, Law, Government, and Judiciary\n",
              "17  Why do girls want to be friends with the guy t...  ...   Recreation, Sports, Travel & Activities\n",
              "18  Why are so many Quora users posting questions ...  ...                           Major Concepts \n",
              "19  Which is the best digital marketing institutio...  ...         News, Entertainment & Pop culture\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33i3TFi28740",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the labled data as quora_supervised\n",
        "from google.colab import files\n",
        "question_df.to_csv('quora_supervised.csv',sep='\\t', encoding='utf-8') \n",
        "files.download('quora_supervised.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vawAYFykG4kG",
        "colab_type": "text"
      },
      "source": [
        "Q 2\n",
        "**Supervised Machine learning**\n",
        "\n",
        "The best performing algorithm can be chosen by creating confusion matrix or finding evaluation matrix and calculate Accuracy, Precision, Recall and F1 score.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWn8EQLrORYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "127222cf-449e-4a21-a043-7cda5e0db317"
      },
      "source": [
        "#Impoting required libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Spiltting data into input features and corresponding outputs\n",
        "sentences = question_df['question'].values\n",
        "y = question_df['Topic number'].values\n",
        "\n",
        "#Spiltting data into Train and Test.\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000)\n",
        "\n",
        "# Creating term frequency matrix\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(sentences_train.astype('U'))\n",
        "\n",
        "X_train = vectorizer.transform(sentences_train.astype('U'))\n",
        "X_test  = vectorizer.transform(sentences_test.astype('U'))\n",
        "X_train"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<150000x44693 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1494343 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAIUs5wxTJEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "51a87380-3e6d-4381-e41b-431b0c9c829a"
      },
      "source": [
        "# Creating a Classifier using Logistic Regression.\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "score = classifier.score(X_test, y_test)\n",
        "\n",
        "print(\"Accuracy:\", score)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.92546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUFhy2mzcj-2",
        "colab_type": "text"
      },
      "source": [
        "Creating a Confusion Matrix for model evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mdoCHPacHZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8b9dd9d4-23bb-4caa-fe07-365d79c6a40b"
      },
      "source": [
        "from sklearn import metrics\n",
        "predictions = classifier.predict(X_test)\n",
        "predictions\n",
        "print(metrics.confusion_matrix(y_test,predictions))\n",
        "# # You can make the confusion matrix less confusing "
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6504  158   61  115   76  124   26   92   85  116   43   66  301]\n",
            " [ 138 6986  122  126   59   85   36  160  194  130   53   55  198]\n",
            " [  71  120 4651   49  110   47   30  108   27   66   15   33   67]\n",
            " [  78   84   28 6619  248  230   77  172   86  129   42  195  173]\n",
            " [  86  109   95  240 7198  114   86  184  128  102   49  104  119]\n",
            " [  99   71   26  214   80 8322  111  111   64  119   34  166  110]\n",
            " [  50   45   28  100   73  120 5545  139   31   71   33   94   81]\n",
            " [  84  163   74  149  168  103   93 6820  170  101   39  113  279]\n",
            " [  87  181   28  107  104  109   24  183 7192  121   65   72  144]\n",
            " [ 164  202   84  195  141  167   65  218  152 5695  103  195  211]\n",
            " [  58   70   31   95   79   84   33   44   65   90 3648   56  150]\n",
            " [  64   86   43  233  122  191  100  168  108  188   44 5725  243]\n",
            " [ 153  196   51  193  132  139   56  246  104  164   79  161 7928]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ3iyPEhD0cN",
        "colab_type": "text"
      },
      "source": [
        "Classification Report of Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vwMJLFPmDXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "18ffa19b-7e14-4f4c-fa58-ddd3cb2de3db"
      },
      "source": [
        "print(metrics.classification_report(y_test,predictions))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.84      7767\n",
            "           1       0.82      0.84      0.83      8342\n",
            "           2       0.87      0.86      0.87      5394\n",
            "           3       0.78      0.81      0.80      8161\n",
            "           4       0.84      0.84      0.84      8614\n",
            "           5       0.85      0.87      0.86      9527\n",
            "           6       0.88      0.87      0.87      6410\n",
            "           7       0.79      0.82      0.80      8356\n",
            "           8       0.86      0.85      0.86      8417\n",
            "           9       0.80      0.75      0.78      7592\n",
            "          10       0.86      0.81      0.83      4503\n",
            "          11       0.81      0.78      0.80      7315\n",
            "          12       0.79      0.83      0.81      9602\n",
            "\n",
            "    accuracy                           0.83    100000\n",
            "   macro avg       0.83      0.83      0.83    100000\n",
            "weighted avg       0.83      0.83      0.83    100000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a9N0zZKrDU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "# Setting gamma to \"auto\", otherwise the SVC model \n",
        "# returns an error\n",
        "svc_model = SVC(gamma=\"auto\")\n",
        "svc_model.fit(X_train, y_train)\n",
        "\n",
        "svc_model_predictions = svc_model.predict(X_test)\n",
        "\n",
        "print(metrics.confusion_matrix(y_test, svc_model_predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIURnukLrKv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "# Create an instance of the model - common model for text data and spam filtering\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Fit model to training data\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict answers to data from the X_text dataset\n",
        "# containing text length and punctuation count\n",
        "rf_model_predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Show results in a confusion matrix\n",
        "print(metrics.confusion_matrix(y_test,rf_model_predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtkM9cv6CQRZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "77f17e08-cd43-46ca-e8c4-640ecd944b4d"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_test,rf_model_predictions))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10119     8    21    42    74   148     3    18    35     4   133    26\n",
            "      0]\n",
            " [  127  1599     1     6    25    42     0     3     9     0    39     9\n",
            "      0]\n",
            " [  267     4  1916     4    33    73     0    13     5     2    41    14\n",
            "      0]\n",
            " [  313    10    12  2214    50    81     0     6    14     3    76    25\n",
            "      3]\n",
            " [  835    10    19    28  5070    89     0    20    17     6   156    28\n",
            "      0]\n",
            " [  425     3    20     9    82  5899     2    19    23     2   105    26\n",
            "      0]\n",
            " [   82     4     8     2     7    32  1090     1     3     5    14    16\n",
            "      1]\n",
            " [  195     2     4     1    50    31     2  1735     5     1    20     8\n",
            "      0]\n",
            " [  377     6     5    15    46    99     2     6  2724     0    44    14\n",
            "      1]\n",
            " [   46     0     1     0    12     4     0     0     1  1121     6     0\n",
            "      0]\n",
            " [  603    21    14    43   112   178     2    15    40     4  6100    29\n",
            "      1]\n",
            " [  372     2    22     4    53   106     3     8    14     1    40  2749\n",
            "      0]\n",
            " [   91     3     3    18    28    26     1     3     6     2    41    17\n",
            "    813]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZpxUfHfDuei",
        "colab_type": "text"
      },
      "source": [
        "Classification report of Random_Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vetHNBaCfbF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a3b3c10b-70db-42e9-ef38-414b9b589644"
      },
      "source": [
        "print(metrics.classification_report(y_test,rf_model_predictions))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.95      0.83     10631\n",
            "           1       0.96      0.86      0.91      1860\n",
            "           2       0.94      0.81      0.87      2372\n",
            "           3       0.93      0.79      0.85      2807\n",
            "           4       0.90      0.81      0.85      6278\n",
            "           5       0.87      0.89      0.88      6615\n",
            "           6       0.99      0.86      0.92      1265\n",
            "           7       0.94      0.84      0.89      2054\n",
            "           8       0.94      0.82      0.87      3339\n",
            "           9       0.97      0.94      0.96      1191\n",
            "          10       0.90      0.85      0.87      7162\n",
            "          11       0.93      0.81      0.87      3374\n",
            "          12       0.99      0.77      0.87      1052\n",
            "\n",
            "    accuracy                           0.86     50000\n",
            "   macro avg       0.92      0.85      0.88     50000\n",
            "weighted avg       0.88      0.86      0.86     50000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tocmKHWNrToU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6f02e3b7-3bf3-4585-b901-0245b5e0ac3f"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Create an instance of the model - common model for text data and spam filtering\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Fit model to training data\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict answers to data from the X_text dataset\n",
        "# containing text length and punctuation count\n",
        "nb_model_predictions = nb_model.predict(X_test)\n",
        "\n",
        "# Show results in a confusion matrix\n",
        "print(metrics.confusion_matrix(y_test,nb_model_predictions))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7953   50   49   83  602  667    7   68  161   42  778  168    3]\n",
            " [ 108 1155    8   61  128  111    0    5   41    1  200   41    1]\n",
            " [ 192    8 1449   17  146  325    1   13   27    4  132   58    0]\n",
            " [ 202    6   22 1860  161  174    1    6   38    5  293   32    7]\n",
            " [ 355   54   21   39 4925  235    2   38   34   13  474   88    0]\n",
            " [ 273   21   55   54  284 5363    4   24   75   17  334  111    0]\n",
            " [ 103    8   54   15   21  157  810    6    8    5   46   29    3]\n",
            " [ 122    1   30    6  225  131    0 1403   11    1   88   36    0]\n",
            " [ 237   39   16   59  125  248    1   10 2360    0  197   44    3]\n",
            " [  35    0    8    3   42   17    1    1    2 1048   25    8    1]\n",
            " [ 287   31   42   94  246  327    3   23   81    3 5945   74    6]\n",
            " [ 442    9   31   25  203  343    2   25   53    1  117 2123    0]\n",
            " [  75    1    5   64   43   32   11    8   22    2  161   29  599]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oeCP89mD-0V",
        "colab_type": "text"
      },
      "source": [
        "Classification Report of Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pk28T_READw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "bbeeb500-3b9c-411c-84a7-1d713713b545"
      },
      "source": [
        "print(metrics.classification_report(y_test,nb_model_predictions))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.75      0.76     10631\n",
            "           1       0.84      0.62      0.71      1860\n",
            "           2       0.81      0.61      0.70      2372\n",
            "           3       0.78      0.66      0.72      2807\n",
            "           4       0.69      0.78      0.73      6278\n",
            "           5       0.66      0.81      0.73      6615\n",
            "           6       0.96      0.64      0.77      1265\n",
            "           7       0.86      0.68      0.76      2054\n",
            "           8       0.81      0.71      0.75      3339\n",
            "           9       0.92      0.88      0.90      1191\n",
            "          10       0.68      0.83      0.75      7162\n",
            "          11       0.75      0.63      0.68      3374\n",
            "          12       0.96      0.57      0.72      1052\n",
            "\n",
            "    accuracy                           0.74     50000\n",
            "   macro avg       0.81      0.71      0.74     50000\n",
            "weighted avg       0.75      0.74      0.74     50000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKP3BglCdF4r",
        "colab_type": "text"
      },
      "source": [
        "Creating a Deep Neural Architecture for Text Classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byqIz_rsbD3P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b451d70d-4f29-4530-ebd8-4b82cdc17921"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from numpy import array\n",
        "\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CAamcGMdA4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "37fbbe43-07fa-4c97-fa2f-2c38e73e666a"
      },
      "source": [
        " model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 10)                446940    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 446,951\n",
            "Trainable params: 446,951\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNs3u2YjcrXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " history = model.fit(X_train, y_train,epochs=100,verbose=False,validation_data=(X_test, y_test),batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak0Z3qd5c5-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        " loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmTXwfIQlbd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "print(sentences_train[2])\n",
        "print(X_train[2])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}